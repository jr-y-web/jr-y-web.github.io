姓名： 叶锦荣
主题： 为什么需要检索增强生成技术（RAG）

首先，最为关键还是来自幻觉问题，因为 LMM 是基于庞大的数据中训练出来的概率模型来一个个生成 token，通俗的说它没有逻辑以及事实的基线，因此 LMM 存在的智能也只是“涌现性的智能”，它基于概率产生的“伪智能”，不同于“真智能”来自基于逻辑、推理、演算的能力。“涌现性的智能”说白了只要模型足够大、训练的数据集足够大，那么它所反馈的内容正确的概念也足够大，但这样就会产生很多问题。举个例子，这里向 AI 提问提供数个代表高兴的颜色，这个时候 ai 返回大多是红色或者橙色相关的高亮色系，但 AI 能理解“高兴”情感下的颜色嘛？可能有人会认为自己高兴的颜色是一无边界的白，不是亮色系呢？显然，它所回答的是基于训练中亮色系颜色对“高兴”产生了足够的联系，所以回答也是往这个方向罢了。另外对领域知识的欠缺。这部分分两种情况，第一种是对知识的更新慢，例如你问他最新的新闻他肯定是不知道的，因为他的训练数据集不可能每天更新；第二种是特定领域的知识不了解，比如某个模型刚好在这个领域的训练过于少，那它就特别容易产生幻觉问题，然后就纯瞎回答，因此对于公司内部特定知识库，那更容易产生幻觉问题了。
因此，特别需要 RAG，从翻译也能得知，它核心流程就是检索 => 增强 => 生成，它就是为了上述亮点问题进行解决，给予结果一个“精准的智能”。
